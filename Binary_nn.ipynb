{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A binary classification Neural Network #\n",
    "\n",
    "Purpose of this notebook :\n",
    "\n",
    "- create a binary classification neural network from scratch\n",
    "- practice oop programming\n",
    "- practice docstring and commentaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add useful librairies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (2, 900)\n",
      "Y :  (1, 900)\n",
      "X_test :  (2, 100)\n",
      "Y_test :  (1, 100)\n"
     ]
    }
   ],
   "source": [
    "# First the full neural network\n",
    "\n",
    "# The prupose is to predict from data\n",
    "# let's create some data a XOR problematic\n",
    "\n",
    "# Let's fix ou random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# A dataset of m example with 2 inputs shape(2 m)\n",
    "X = np.random.randn(2, 1000)\n",
    "# Transorm inputs in O. or 1.\n",
    "X = (X > 0.5) * 1.\n",
    "\n",
    "# The labels (when x = (0 0) or (1 1) > False, x = (0 1) or (1 0) > True)\n",
    "Y = (np.sum(X, axis=0, keepdims=True) == 1) * 1.\n",
    "\n",
    "# Add a test set\n",
    "train_size = int(X.shape[1] * 0.9)\n",
    "X_test = X[:,train_size:]\n",
    "Y_test = Y[:,train_size:]\n",
    "X = X[:,:train_size]\n",
    "Y = Y[:,:train_size]\n",
    "\n",
    "\n",
    "print('X : ', X.shape)\n",
    "print('Y : ', Y.shape)\n",
    "print('X_test : ', X_test.shape)\n",
    "print('Y_test : ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 90)\n",
      "(1, 90)\n",
      "(2, 10)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Créer un dataset séparable par une ligne droite en 2D\n",
    "\n",
    "def split_dataset(X, y, train_pct=0.66):\n",
    "    \"\"\" Va séparer les datasets avec respect pour le pourcentage du dataset à mettre dans le train set.\n",
    "    Warning: La dimension des exemples doit être la première.\n",
    "    Warnings2: Cette fonction doit recevoir des exemples déjà mélangé (car splité en fonction des index)\n",
    "    \n",
    "    TODO: Rajouter un argument pour mélanger les dataset\n",
    "    \n",
    "    :X mes exemples, shape=(m, -1), m -> dimensions des exemples\n",
    "    :y mes labels, shape=(m, -1), m -> dimensions des exemples\n",
    "    :train_pct (default=0.66) Optionnal, c'est un pourcentage qui va séparer le de dataset avec train_pct * total_size dans le train set.\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test \n",
    "    \n",
    "\n",
    "    >>> X_train, y_train, X_test, y_test = split_dataset(X, y)\n",
    "    \"\"\"\n",
    "    # 2ème dimension -> celle des exemples\n",
    "    total_size = X.shape[1]\n",
    "    \n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(1, -1)\n",
    "    \n",
    "    # On récupère `train_pct` % du dataset pour le train set, aussi il faut convertir en entier pour numpy ...\n",
    "    train_size = int(train_pct * total_size)\n",
    "    # ... et on met le reste danss le test set\n",
    "    test_size  = total_size - train_size \n",
    "    \n",
    "    # On met les `train_size` premier exemples/labels dans le train set ...\n",
    "    X_train, y_train = (X[:,:train_size], y[:,:train_size])\n",
    "    # ... et les test_size derniers exemples/labels dans le test set.\n",
    "    X_test , y_test  = (X[:,-test_size:], y[:,-test_size:])\n",
    "\n",
    "    # On s'assure que tous les exemples soient présents dans le test set ou le train set.\n",
    "    assert X_test.shape[1] + X_train.shape[1] == total_size\n",
    "    assert y_test.shape[1] + y_train.shape[1] == total_size\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X = np.zeros((2,100))\n",
    "Y = np.zeros((1,100))\n",
    "\n",
    "a, b, c, d = split_dataset(X,Y,0.9)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 180)\n",
      "(1, 180)\n",
      "(2, 20)\n",
      "(1, 20)\n"
     ]
    }
   ],
   "source": [
    "# SET de MOON\n",
    "# On fixe le nombre d'example total par dataset à SAMPLE_SIZE\n",
    "SAMPLE_SIZE = 200\n",
    "\n",
    "# Fixer le hasard\n",
    "np.random.seed(666)\n",
    "\n",
    "# On crée le dataset séparable linéarement\n",
    "X, Y = make_moons(n_samples = SAMPLE_SIZE,\n",
    "                          shuffle = True,\n",
    "                          noise = 0.1)\n",
    "\n",
    "X = X.T\n",
    "Y = Y.T\n",
    "\n",
    "# On split le dataset en set de training et de test\n",
    "X, Y, X_test, Y_test = split_dataset(X, Y, 0.9)\n",
    "\n",
    "# On affiche le shape pour la forme\n",
    "for each in (X, Y, X_test, Y_test):\n",
    "    print(each.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coding the sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# testons la sigmoid\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7646146824783532\n",
      "0.3645921697784976\n",
      "0.3543592463984894\n",
      "0.2819548187667688\n",
      "0.2154173078100468\n",
      "0.2718931832026733\n",
      "0.2064058605477193\n",
      "0.19936981819405494\n",
      "0.1918282751461711\n",
      "0.18410290851144914\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train set :  93.88888888888889\n",
      "Loss test set :  0.18626856309992101\n",
      "Accuracy test set :  90.0\n"
     ]
    }
   ],
   "source": [
    "# let's concatenate all our cells\n",
    "\n",
    "# parameters\n",
    "np.random.seed(42)\n",
    "hidden_layers = [4]\n",
    "iteration = 1000\n",
    "learning_rate = 0.4\n",
    "\n",
    "layers = [X.shape[0]] + hidden_layers + [1]\n",
    "# we need a list to store our costs\n",
    "costs = []\n",
    "\n",
    "# Initialisation of list Weights and bias shape (output_layer(-1) layer) (output_layer(-1) 1)\n",
    "W = [np.random.randn(layers[k], layers[k-1]) for k in range(1, len(layers))]\n",
    "b = [np.zeros((layers[k], 1)) for k in range(1, len(layers))]\n",
    "\n",
    "# training loop\n",
    "for k in range(iteration):\n",
    "    # Forward -------------------------------------------------\n",
    "    # Let's make a list of activation starting with the inputs matrix\n",
    "    activation = [X]\n",
    "    # Loop to pass through all neurons\n",
    "    for l in range(len(layers)-1):\n",
    "    #     print(activation[l],' * ',W[l],' + ',b)\n",
    "        pre_activation = np.dot(W[l], activation[l]) + b[l]\n",
    "    #     print('preactivation :',pre_activation)\n",
    "        activation.append(sigmoid(pre_activation))\n",
    "\n",
    "    # loss and cost ----------------------------------\n",
    "    prediction_inter = activation[-1]\n",
    "    # loss function\n",
    "    loss = -Y * np.log(prediction_inter) - (1 - Y) * np.log(1 - prediction_inter)\n",
    "    # number of examples\n",
    "    m = X.shape[1]\n",
    "    # Cost function\n",
    "    cost = np.sum(loss) / m\n",
    "    if k % 100 == 0:\n",
    "        print(cost)\n",
    "    # Cost storage\n",
    "    costs.append(cost)\n",
    "\n",
    "    # Backward --------------------------------------------------\n",
    "\n",
    "    # First the last layer\n",
    "    d_loss = -Y/activation[-1] + (1-Y)/(1-activation[-1])\n",
    "    d_activation = activation[-1] * (1 - activation[-1])\n",
    "    d_pre_activation = d_loss * d_activation\n",
    "#     d_pre_activation = (activation[-1] - Y)\n",
    "\n",
    "    d_W = [np.dot(d_pre_activation, activation[-2].T)]\n",
    "    d_b = [np.sum(d_pre_activation, axis=1, keepdims=True) / m]\n",
    "\n",
    "    # Loop for the next layers\n",
    "    for l in reversed(range(1, len(layers)-1)):\n",
    "        d_pre_activation = np.dot(W[l].T, d_pre_activation)\n",
    "        d_pre_activation_sig = d_pre_activation * (activation[l] * (1 - activation[l]))\n",
    "\n",
    "        d_W.insert(0, np.dot(d_pre_activation_sig, activation[l-1].T))\n",
    "        d_b.insert(0, np.sum(d_pre_activation_sig, axis=1, keepdims=True) / m)\n",
    "\n",
    "    # updating the parameters\n",
    "    # Loop for updating all weights and bias in the network\n",
    "    for i in range(len(layers)-1):\n",
    "        W[i] -= learning_rate * d_W[i]\n",
    "        b[i] -= learning_rate * d_b[i]\n",
    "\n",
    "# Let's show the loss evolution\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "# Let's compute the accuracy\n",
    "prediction = (activation[-1] > 0.5) * 1\n",
    "accuracy = (1 - np.mean(np.abs(Y - prediction))) * 100\n",
    "print('Accuracy train set : ', accuracy)\n",
    "        \n",
    "# Now the test set to compare\n",
    "# Forward -------------------------------------------------\n",
    "# Let's make a list of activation starting with the inputs matrix\n",
    "activation_test = [X_test]\n",
    "# Loop to pass through all neurons\n",
    "for l in range(len(layers)-1):\n",
    "    pre_activation = np.dot(W[l], activation_test[l]) + b[l]\n",
    "    activation_test.append(sigmoid(pre_activation))\n",
    "\n",
    "# loss and cost ----------------------------------\n",
    "prediction_test_inter = activation_test[-1]\n",
    "# loss function\n",
    "loss_test = -Y_test * np.log(prediction_test_inter) - (1 - Y_test) * np.log(1 - prediction_test_inter)\n",
    "# number of examples\n",
    "m_test = X_test.shape[1]\n",
    "# Cost function\n",
    "cost_test = np.sum(loss) / m_test\n",
    "print('Loss test set : ', cost)\n",
    "    \n",
    "# Let's compute the accuracy\n",
    "prediction_test = (activation_test[-1] > 0.5) * 1\n",
    "accuracy_test = (1 - np.mean(np.abs(Y_test - prediction_test))) * 100\n",
    "print('Accuracy test set : ', accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
