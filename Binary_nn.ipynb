{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A binary classification Neural Network #\n",
    "\n",
    "Purpose of this notebook :\n",
    "\n",
    "- create a binary classification neural network from scratch\n",
    "- practice oop programming\n",
    "- practice docstring and commentaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add useful librairies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (2, 900)\n",
      "Y :  (1, 900)\n",
      "X_test :  (2, 100)\n",
      "Y_test :  (1, 100)\n"
     ]
    }
   ],
   "source": [
    "# First the full neural network\n",
    "\n",
    "# The prupose is to predict from data\n",
    "# let's create some data a XOR problematic\n",
    "\n",
    "# Let's fix ou random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# A dataset of m example with 2 inputs shape(2 m)\n",
    "X = np.random.randn(2, 1000)\n",
    "# Transorm inputs in O. or 1.\n",
    "X = (X > 0.5) * 1.\n",
    "\n",
    "# The labels (when x = (0 0) or (1 1) > False, x = (0 1) or (1 0) > True)\n",
    "Y = (np.sum(X, axis=0, keepdims=True) == 1) * 1.\n",
    "\n",
    "# Add a test set\n",
    "train_size = int(X.shape[1] * 0.9)\n",
    "X_test = X[:,train_size:]\n",
    "Y_test = Y[:,train_size:]\n",
    "X = X[:,:train_size]\n",
    "Y = Y[:,:train_size]\n",
    "\n",
    "\n",
    "print('X : ', X.shape)\n",
    "print('Y : ', Y.shape)\n",
    "print('X_test : ', X_test.shape)\n",
    "print('Y_test : ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coding the sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# testons la sigmoid\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6807587205297175\n",
      "0.26334727269744007\n",
      "0.2632886308836291\n",
      "0.26328840164141026\n",
      "0.2632882567327823\n",
      "0.26328813038306154\n",
      "0.26328801916020056\n",
      "0.26328792046966526\n",
      "0.263287832279249\n",
      "0.26328775297447227\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train set :  89.55555555555556\n",
      "Loss test set :  0.2632876819397267\n",
      "Accuracy test set :  90.0\n"
     ]
    }
   ],
   "source": [
    "# let's concatenate all our cells\n",
    "\n",
    "# parameters\n",
    "np.random.seed(42)\n",
    "hidden_layers = [4]\n",
    "iteration = 1000\n",
    "learning_rate = 0.4\n",
    "\n",
    "layers = [X.shape[0]] + hidden_layers + [1]\n",
    "# we need a list to store our costs\n",
    "costs = []\n",
    "\n",
    "# Initialisation of list Weights and bias shape (output_layer(-1) layer) (output_layer(-1) 1)\n",
    "W = [np.random.randn(layers[k], layers[k-1]) for k in range(1, len(layers))]\n",
    "b = [np.zeros((layers[k], 1)) for k in range(1, len(layers))]\n",
    "\n",
    "# training loop\n",
    "for k in range(iteration):\n",
    "    # Forward -------------------------------------------------\n",
    "    # Let's make a list of activation starting with the inputs matrix\n",
    "    activation = [X]\n",
    "    # Loop to pass through all neurons\n",
    "    for l in range(len(layers)-1):\n",
    "    #     print(activation[l],' * ',W[l],' + ',b)\n",
    "        pre_activation = np.dot(W[l], activation[l]) + b[l]\n",
    "    #     print('preactivation :',pre_activation)\n",
    "        activation.append(sigmoid(pre_activation))\n",
    "\n",
    "    # loss and cost ----------------------------------\n",
    "    prediction_inter = activation[-1]\n",
    "    # loss function\n",
    "    loss = -Y * np.log(prediction_inter) - (1 - Y) * np.log(1 - prediction_inter)\n",
    "    # number of examples\n",
    "    m = X.shape[1]\n",
    "    # Cost function\n",
    "    cost = np.sum(loss) / m\n",
    "    if k % 100 == 0:\n",
    "        print(cost)\n",
    "    # Cost storage\n",
    "    costs.append(cost)\n",
    "\n",
    "    # Backward --------------------------------------------------\n",
    "\n",
    "    # First the last layer\n",
    "#     d_loss = -Y/activation[-1] + (1-Y)/(1-activation[-1])\n",
    "#     d_activation = activation[-1] * (1 - activation[-1])\n",
    "#     d_pre_activation = d_loss * d_activation\n",
    "    d_pre_activation = (activation[-1] - Y)\n",
    "\n",
    "    d_W = [np.dot(d_pre_activation, activation[-2].T)]\n",
    "    d_b = [np.sum(d_pre_activation, axis=1, keepdims=True) / m]\n",
    "\n",
    "    # Loop for the next layers\n",
    "    for l in reversed(range(1, len(layers)-1)):\n",
    "        d_pre_activation = np.dot(W[l].T, d_pre_activation)\n",
    "        d_pre_activation_sig = d_pre_activation * (activation[l] * (1 - activation[l]))\n",
    "\n",
    "        d_W.insert(0, np.dot(d_pre_activation_sig, activation[l-1].T))\n",
    "        d_b.insert(0, np.sum(d_pre_activation_sig, axis=1, keepdims=True) / m)\n",
    "\n",
    "    # updating the parameters\n",
    "    # Loop for updating all weights and bias in the network\n",
    "    for i in range(len(layers)-1):\n",
    "        W[i] -= learning_rate * d_W[i]\n",
    "        b[i] -= learning_rate * d_b[i]\n",
    "\n",
    "# Let's show the loss evolution\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "# Let's compute the accuracy\n",
    "prediction = (activation[-1] > 0.5) * 1\n",
    "accuracy = (1 - np.mean(np.abs(Y - prediction))) * 100\n",
    "print('Accuracy train set : ', accuracy)\n",
    "        \n",
    "# Now the test set to compare\n",
    "# Forward -------------------------------------------------\n",
    "# Let's make a list of activation starting with the inputs matrix\n",
    "activation_test = [X_test]\n",
    "# Loop to pass through all neurons\n",
    "for l in range(len(layers)-1):\n",
    "    pre_activation = np.dot(W[l], activation_test[l]) + b[l]\n",
    "    activation_test.append(sigmoid(pre_activation))\n",
    "\n",
    "# loss and cost ----------------------------------\n",
    "prediction_test_inter = activation_test[-1]\n",
    "# loss function\n",
    "loss_test = -Y_test * np.log(prediction_test_inter) - (1 - Y_test) * np.log(1 - prediction_test_inter)\n",
    "# number of examples\n",
    "m_test = X_test.shape[1]\n",
    "# Cost function\n",
    "cost_test = np.sum(loss) / m_test\n",
    "print('Loss test set : ', cost)\n",
    "    \n",
    "# Let's compute the accuracy\n",
    "prediction_test = (activation_test[-1] > 0.5) * 1\n",
    "accuracy_test = (1 - np.mean(np.abs(Y_test - prediction_test))) * 100\n",
    "print('Accuracy test set : ', accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
