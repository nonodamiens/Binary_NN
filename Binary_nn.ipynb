{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A binary classification Neural Network #\n",
    "\n",
    "Purpose of this notebook :\n",
    "\n",
    "- create a binary classification neural network from scratch\n",
    "- practice oop programming\n",
    "- practice docstring and commentaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add useful librairies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  (2, 4000)\n",
      "Y :  (1, 4000)\n",
      "X_test :  (2, 400)\n",
      "Y_test :  (1, 400)\n"
     ]
    }
   ],
   "source": [
    "# First the full neural network\n",
    "\n",
    "# The prupose is to predict from data\n",
    "# let's create some data a XOR problematic\n",
    "\n",
    "# Let's fix ou random seed\n",
    "np.random.seed(2)\n",
    "\n",
    "# A dataset of m example with 2 inputs shape(2 m)\n",
    "X = np.random.randn(2, 4000)\n",
    "# Transorm inputs in O. or 1.\n",
    "X = (X > 0.5) * 1.\n",
    "\n",
    "# The labels (when x = (0 0) or (1 1) > False, x = (0 1) or (1 0) > True)\n",
    "Y = (np.sum(X, axis=0, keepdims=True) == 1) * 1.\n",
    "\n",
    "# Add a test set\n",
    "X_test = np.random.randn(2, 400)\n",
    "# Transorm inputs in O. or 1.\n",
    "X_test = (X_test > 0.5) * 1.\n",
    "\n",
    "# The labels (when x = (0 0) or (1 1) > False, x = (0 1) or (1 0) > True)\n",
    "Y_test = (np.sum(X_test, axis=0, keepdims=True) == 1) * 1.\n",
    "\n",
    "print('X : ', X.shape)\n",
    "print('Y : ', Y.shape)\n",
    "print('X_test : ', X_test.shape)\n",
    "print('Y_test : ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 90)\n",
      "(1, 90)\n",
      "(2, 10)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Créer un dataset séparable par une ligne droite en 2D\n",
    "\n",
    "def split_dataset(X, y, train_pct=0.66):\n",
    "    \"\"\" Va séparer les datasets avec respect pour le pourcentage du dataset à mettre dans le train set.\n",
    "    Warning: La dimension des exemples doit être la première.\n",
    "    Warnings2: Cette fonction doit recevoir des exemples déjà mélangé (car splité en fonction des index)\n",
    "    \n",
    "    TODO: Rajouter un argument pour mélanger les dataset\n",
    "    \n",
    "    :X mes exemples, shape=(m, -1), m -> dimensions des exemples\n",
    "    :y mes labels, shape=(m, -1), m -> dimensions des exemples\n",
    "    :train_pct (default=0.66) Optionnal, c'est un pourcentage qui va séparer le de dataset avec train_pct * total_size dans le train set.\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test \n",
    "    \n",
    "\n",
    "    >>> X_train, y_train, X_test, y_test = split_dataset(X, y)\n",
    "    \"\"\"\n",
    "    # 2ème dimension -> celle des exemples\n",
    "    total_size = X.shape[1]\n",
    "    \n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(1, -1)\n",
    "    \n",
    "    # On récupère `train_pct` % du dataset pour le train set, aussi il faut convertir en entier pour numpy ...\n",
    "    train_size = int(train_pct * total_size)\n",
    "    # ... et on met le reste danss le test set\n",
    "    test_size  = total_size - train_size \n",
    "    \n",
    "    # On met les `train_size` premier exemples/labels dans le train set ...\n",
    "    X_train, y_train = (X[:,:train_size], y[:,:train_size])\n",
    "    # ... et les test_size derniers exemples/labels dans le test set.\n",
    "    X_test , y_test  = (X[:,-test_size:], y[:,-test_size:])\n",
    "\n",
    "    # On s'assure que tous les exemples soient présents dans le test set ou le train set.\n",
    "    assert X_test.shape[1] + X_train.shape[1] == total_size\n",
    "    assert y_test.shape[1] + y_train.shape[1] == total_size\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X = np.zeros((2,100))\n",
    "Y = np.zeros((1,100))\n",
    "\n",
    "a, b, c, d = split_dataset(X,Y,0.9)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1800)\n",
      "(1, 1800)\n",
      "(2, 200)\n",
      "(1, 200)\n"
     ]
    }
   ],
   "source": [
    "# SET de MOON\n",
    "# On fixe le nombre d'example total par dataset à SAMPLE_SIZE\n",
    "SAMPLE_SIZE = 2000\n",
    "\n",
    "# Fixer le hasard\n",
    "np.random.seed(666)\n",
    "\n",
    "# On crée le dataset séparable linéarement\n",
    "X, Y = make_moons(n_samples = SAMPLE_SIZE,\n",
    "                          shuffle = True,\n",
    "                          noise = 0.1)\n",
    "\n",
    "X = X.T\n",
    "Y = Y.T\n",
    "\n",
    "# On split le dataset en set de training et de test\n",
    "X, Y, X_test, Y_test = split_dataset(X, Y, 0.9)\n",
    "\n",
    "# On affiche le shape pour la forme\n",
    "for each in (X, Y, X_test, Y_test):\n",
    "    print(each.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 660)\n",
      "(1, 660)\n",
      "(2, 340)\n",
      "(1, 340)\n",
      "[[ 0.92787748 -0.54303182  0.9246533  ...  0.75209229 -0.69471802\n",
      "  -0.08402948]\n",
      " [-0.04521731 -0.75444674 -0.71492522 ... -0.73132156 -0.90889854\n",
      "  -0.96805179]]\n"
     ]
    }
   ],
   "source": [
    "# CIRCLE SET\n",
    "# On fixe le nombre d'example total par dataset à SAMPLE_SIZE\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "# Fixer le hasard\n",
    "np.random.seed(1)\n",
    "\n",
    "# On crée le dataset séparable linéarement\n",
    "X, y = make_circles(n_samples = SAMPLE_SIZE,\n",
    "                          shuffle = True,\n",
    "                          noise = 0.1)\n",
    "X = X.T\n",
    "y = y.T\n",
    "\n",
    "# On split le dataset en set de training et de test\n",
    "X, Y, X_test, Y_test = split_dataset(X, y)\n",
    "\n",
    "# On affiche le shape pour la forme\n",
    "for each in (X, Y, X_test, Y_test):\n",
    "    print(each.shape)\n",
    "    \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coding the sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# testons la sigmoid\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90243391 -0.56847539  0.89920974 ...  0.72664872 -0.72016158\n",
      "  -0.10947305]\n",
      " [-0.07066087 -0.77989031 -0.74036878 ... -0.75676513 -0.93434211\n",
      "  -0.99349536]]\n",
      "[[ 0.74011604 -0.46622556  0.73747179 ...  0.59594876 -0.59062845\n",
      "  -0.08978248]\n",
      " [-0.05795133 -0.63961396 -0.60720104 ... -0.62064823 -0.76628501\n",
      "  -0.81479856]]\n"
     ]
    }
   ],
   "source": [
    "# Normalisation\n",
    "X = X - (np.amax(X) + np.amin(X)) / 2\n",
    "print(X)\n",
    "X = X / np.amax(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6698491558540179\n",
      "0.5102559869198598\n",
      "0.3818426434515402\n",
      "0.3150181281031356\n",
      "0.2806020962488036\n",
      "0.25790863950692233\n",
      "0.23798719571243898\n",
      "0.2177816969099364\n",
      "0.19748868569822722\n",
      "0.17688891441420407\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train set :  91.675\n",
      "Loss test set :  0.15649935351724145\n",
      "Accuracy test set :  88.0\n"
     ]
    }
   ],
   "source": [
    "# let's concatenate all our cells\n",
    "\n",
    "# parameters\n",
    "np.random.seed(2)\n",
    "hidden_layers = [3]\n",
    "iteration = 1000\n",
    "learning_rate = 0.3\n",
    "\n",
    "layers = [X.shape[0]] + hidden_layers + [1]\n",
    "# we need a list to store our costs\n",
    "costs = []\n",
    "\n",
    "# Initialisation of list Weights and bias shape (output_layer(-1) layer) (output_layer(-1) 1)\n",
    "W = [np.random.randn(layers[k], layers[k-1]) for k in range(1, len(layers))]\n",
    "b = [np.zeros((layers[k], 1)) for k in range(1, len(layers))]\n",
    "\n",
    "# training loop\n",
    "for k in range(iteration):\n",
    "    # Forward -------------------------------------------------\n",
    "    # Let's make a list of activation starting with the inputs matrix\n",
    "    activation = [X]\n",
    "    # Loop to pass through all neurons\n",
    "    for l in range(len(layers)-1):\n",
    "    #     print(activation[l],' * ',W[l],' + ',b)\n",
    "        pre_activation = np.dot(W[l], activation[l]) + b[l]\n",
    "    #     print('preactivation :',pre_activation)\n",
    "        activation.append(sigmoid(pre_activation))\n",
    "\n",
    "    # loss and cost ----------------------------------\n",
    "    prediction_inter = activation[-1]\n",
    "    # loss function\n",
    "    loss = -Y * np.log(prediction_inter) - (1 - Y) * np.log(1 - prediction_inter)\n",
    "    # number of examples\n",
    "    m = X.shape[1]\n",
    "    # Cost function\n",
    "    cost = np.sum(loss) / m\n",
    "    if k % 100 == 0:\n",
    "        print(cost)\n",
    "    # Cost storage\n",
    "    costs.append(cost)\n",
    "\n",
    "    # Backward --------------------------------------------------\n",
    "\n",
    "    # First the last layer\n",
    "    d_loss = -Y/activation[-1] + (1-Y)/(1-activation[-1])\n",
    "    d_activation = activation[-1] * (1 - activation[-1])\n",
    "    d_pre_activation = d_loss * d_activation\n",
    "#     d_pre_activation = (activation[-1] - Y)\n",
    "\n",
    "    d_W = [np.dot(d_pre_activation, activation[-2].T) / m]\n",
    "    d_b = [np.sum(d_pre_activation, axis=1, keepdims=True) / m]\n",
    "\n",
    "    # Loop for the next layers\n",
    "    for l in reversed(range(1, len(layers)-1)):\n",
    "        d_pre_activation = np.dot(W[l].T, d_pre_activation)\n",
    "        d_pre_activation_sig = d_pre_activation * (activation[l] * (1 - activation[l]))\n",
    "\n",
    "        d_W.insert(0, np.dot(d_pre_activation_sig, activation[l-1].T) / m)\n",
    "        d_b.insert(0, np.sum(d_pre_activation_sig, axis=1, keepdims=True) / m)\n",
    "\n",
    "    # updating the parameters\n",
    "    # Loop for updating all weights and bias in the network\n",
    "    for i in range(len(layers)-1):\n",
    "        W[i] -= learning_rate * d_W[i]\n",
    "        b[i] -= learning_rate * d_b[i]\n",
    "\n",
    "# Let's show the loss evolution\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "# Let's compute the accuracy\n",
    "prediction = (activation[-1] > 0.5) * 1\n",
    "accuracy = (1 - np.mean(np.abs(Y - prediction))) * 100\n",
    "print('Accuracy train set : ', accuracy)\n",
    "        \n",
    "# Now the test set to compare\n",
    "# Forward -------------------------------------------------\n",
    "# Let's make a list of activation starting with the inputs matrix\n",
    "activation_test = [X_test]\n",
    "# Loop to pass through all neurons\n",
    "for l in range(len(layers)-1):\n",
    "    pre_activation = np.dot(W[l], activation_test[l]) + b[l]\n",
    "    activation_test.append(sigmoid(pre_activation))\n",
    "\n",
    "# loss and cost ----------------------------------\n",
    "prediction_test_inter = activation_test[-1]\n",
    "# loss function\n",
    "loss_test = -Y_test * np.log(prediction_test_inter) - (1 - Y_test) * np.log(1 - prediction_test_inter)\n",
    "# number of examples\n",
    "m_test = X_test.shape[1]\n",
    "# Cost function\n",
    "cost_test = np.sum(loss) / m_test\n",
    "print('Loss test set : ', cost)\n",
    "    \n",
    "# Let's compute the accuracy\n",
    "prediction_test = (activation_test[-1] > 0.5) * 1\n",
    "accuracy_test = (1 - np.mean(np.abs(Y_test - prediction_test))) * 100\n",
    "print('Accuracy test set : ', accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
